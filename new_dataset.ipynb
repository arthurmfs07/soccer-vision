{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/00--raw/football-field-detection.v15i.yolov5pytorch/train/\"\n",
    "\n",
    "IMG_PATH = f\"{train_path}images/0a2d9b_2_3_png.rf.2b39030ff9f2e93a34aa9ca69abbd77c.jpg\"\n",
    "LBL_PATH = f\"{train_path}/labels/0a2d9b_2_3_png.rf.2b39030ff9f2e93a34aa9ca69abbd77c.txt\"\n",
    "\n",
    "# IMG_PATH = f\"{train_path}images/0a2d9b_6_11_png.rf.2cfd6b6dad39a0f39eee5eb3d729823f.jpg\"\n",
    "# LBL_PATH = f\"{train_path}/labels/0a2d9b_6_11_png.rf.2cfd6b6dad39a0f39eee5eb3d729823f.txt\"\n",
    "\n",
    "\n",
    "# right side\n",
    "# IMG_PATH = f\"{train_path}images/0a2d9b_7_14_png.rf.04beeed5de2d712614d10a1e75aae7b9.jpg\"\n",
    "# LBL_PATH = f\"{train_path}/labels/0a2d9b_7_14_png.rf.04beeed5de2d712614d10a1e75aae7b9.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from src.struct.shared_data   import SharedAnnotations\n",
    "from src.visual.field         import FieldVisualizer, PitchConfig\n",
    "from src.visual.visualizer    import Visualizer\n",
    "\n",
    "# 1) Roboflow → your index mapping\n",
    "rf2my = {\n",
    "    0:   0,\n",
    "    1:   7,\n",
    "    2:  15, \n",
    "    3:  16,\n",
    "    4:   8, \n",
    "    5:   2, \n",
    "    6:  17, \n",
    "    7:  18,\n",
    "    8:   5,\n",
    "    9:   9,\n",
    "    10: 27,\n",
    "    11: 28,\n",
    "    12: 10,\n",
    "    13: 23,\n",
    "    14: 25,\n",
    "    15: 26, \n",
    "    16: 24,\n",
    "    17: 13,\n",
    "    18: 29,\n",
    "    19: 30,\n",
    "    20: 14,\n",
    "    21:  6,\n",
    "    22: 21,\n",
    "    23: 22,\n",
    "    24:  1,\n",
    "    25: 11,\n",
    "    26: 19,\n",
    "    27: 20,\n",
    "    28: 12,# correct until now\n",
    "    29:  3,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# class  xc  yc  w  h   x0  y0  v0   x1  y1  v1   x2  y2  v2 ... xN yN vN\n",
    "\n",
    "# field     count       meaning                                     coordinate space\n",
    "# class\t    1\t        always 0 (only one class: “football field”)\t–\n",
    "# xc yc w h\t4\t        YOLO bounding-box (we normally ignore it)\tnormalised (0-1)\n",
    "# xi yi\t    2 × (N+1)\tposition of landmark i\t                    normalised (0-1)\n",
    "# vi\t    1 × (N+1)\tvisibility flag (0 = not labelled / occluded, 1 = labelled)\n",
    "\n",
    "\n",
    "# 2) load one example\n",
    "IMG = IMG_PATH\n",
    "LBL = LBL_PATH\n",
    "\n",
    "img = cv2.imread(IMG)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# 3) parse Roboflow keypoints\n",
    "vals = list(map(float, open(LBL).read().split()))\n",
    "kp   = np.array(vals[5:], dtype=np.float32).reshape(-1,3)  # (num_pts, 3)\n",
    "\n",
    "# 4) init shared‐data and field\n",
    "shared    = SharedAnnotations()\n",
    "fv        = FieldVisualizer(PitchConfig(draw_points=True))\n",
    "model_pts = fv.get_hardcoded_model_points()  # shape (M,2)\n",
    "\n",
    "# 7) set up the Visualizer\n",
    "class DummyProcess:\n",
    "    def __init__(self, sd):      self.shared_data = sd\n",
    "    def is_done(self):           return True\n",
    "    def on_mouse_click(self, x,y): pass\n",
    "\n",
    "viz = Visualizer(\n",
    "    field_config = PitchConfig(linewidth=2, draw_points=True),\n",
    "    frame        = img,             # initial video frame\n",
    "    class_names  = {}, \n",
    "    process      = DummyProcess(shared)\n",
    ")\n",
    "\n",
    "# prime the video side\n",
    "viz.video_visualizer.update(type(\"VF\",(object,),{\n",
    "    \"frame_id\":0, \"timestamp\":0.0,\n",
    "    \"image\":img,\n",
    "    \"detections\":[]\n",
    "})())\n",
    "\n",
    "# 5) build correspondences\n",
    "pts_img   = []\n",
    "pts_model = []\n",
    "for j, (xn,yn,vis) in enumerate(kp):\n",
    "    if vis <= 0 or j not in rf2my:\n",
    "        continue\n",
    "    my_idx = rf2my[j]\n",
    "\n",
    "    # image‐space pixel\n",
    "    x_px, y_px = float(xn*w), float(yn*h)\n",
    "    shared.captured_video_pts.append((x_px, y_px))\n",
    "    pts_img.append([x_px, y_px])\n",
    "\n",
    "    # model‐space metre\n",
    "    mx, my = model_pts[my_idx]\n",
    "    shared.ground_truth_pts.append((mx, my))\n",
    "    pts_model.append([mx, my])\n",
    "\n",
    "pts_img   = np.array(pts_img,   dtype=np.float32)\n",
    "pts_model = np.array(pts_model, dtype=np.float32)\n",
    "\n",
    "if len(pts_img) > 4:\n",
    "    # 6) fit homography H: model→image\n",
    "    H, _                 = cv2.findHomography(pts_model, pts_img, cv2.RANSAC, 3.0)\n",
    "    shared.H_video2field = H\n",
    "\n",
    "    # ─── EXPERIMENT: random image points → project to model ────────────────────\n",
    "    num_rand = 12\n",
    "    rand_px  = np.column_stack([\n",
    "        np.random.uniform(0, w, num_rand),\n",
    "        np.random.uniform(0, h, num_rand),\n",
    "    ])\n",
    "\n",
    "    # draw these as blue dots on the video\n",
    "    shared.sampled_video_pts = [(float(x), float(y)) for x,y in rand_px]\n",
    "\n",
    "    # now project them into model space via H_inv\n",
    "    H_inv = np.linalg.inv(shared.H_video2field)\n",
    "    rand_model = viz.transform_points(rand_px, H_inv)\n",
    "\n",
    "    # draw these as _model‐space_ blue dots on the field\n",
    "    shared.projected_detection_model_pts = [\n",
    "        (float(mx), float(my)) for mx,my in rand_model\n",
    "    ]\n",
    "\n",
    "# ─── 8) annotate & render ─────────────────────────────────────────────────\n",
    "viz.video_visualizer.clear_annotations()\n",
    "viz.field_visualizer.clear_annotations()\n",
    "viz._annotate_frames(\n",
    "    viz.video_visualizer.frame,\n",
    "    viz.field_visualizer.frame\n",
    ")\n",
    "out = viz.generate_combined_view()\n",
    "\n",
    "# ─── 9) display ────────────────────────────────────────────────────────────\n",
    "display_scale = 0.8  # e.g. 50% of original size\n",
    "out_resized = cv2.resize(out, None, fx=display_scale, fy=display_scale, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "cv2.imshow(\"Random Projection Test\", out_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_homography_pixel2field() missing 1 required positional argument: 'img_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 137\u001b[0m\n\u001b[1;32m    131\u001b[0m             np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mstr\u001b[39m(out_H), H)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Wrote \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m frames + H_pixel2field to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m \u001b[43mclean_dataset_pixel2field\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/00--raw/football-field-detection.v15i.yolov5pytorch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/01--clean/roboflow-pixel2field\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 120\u001b[0m, in \u001b[0;36mclean_dataset_pixel2field\u001b[0;34m(input_dir, output_dir)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_homography_pixel2field\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlbl_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m H \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠ skipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: <4 pts or bad H>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_homography_pixel2field() missing 1 required positional argument: 'img_shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.visual.field import FieldVisualizer, PitchConfig\n",
    "\n",
    "# Roboflow→your‐model index mapping\n",
    "RF2MY = {\n",
    "    0:   0,\n",
    "    1:   7,\n",
    "    2:  15, \n",
    "    3:  16,\n",
    "    4:   8, \n",
    "    5:   2, \n",
    "    6:  17, \n",
    "    7:  18,\n",
    "    8:   5,\n",
    "    9:   9,\n",
    "    10: 27,\n",
    "    11: 28,\n",
    "    12: 10,\n",
    "    13: 23,\n",
    "    14: 25,\n",
    "    15: 26, \n",
    "    16: 24,\n",
    "    17: 13,\n",
    "    18: 29,\n",
    "    19: 30,\n",
    "    20: 14,\n",
    "    21:  6,\n",
    "    22: 21,\n",
    "    23: 22,\n",
    "    24:  1,\n",
    "    25: 11,\n",
    "    26: 19,\n",
    "    27: 20,\n",
    "    28: 12,# correct until now\n",
    "    29:  3,\n",
    "}\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.visual.field import FieldVisualizer, PitchConfig\n",
    "\n",
    "# Roboflow→your‐model index mapping\n",
    "RF2MY = {\n",
    "    0:0, 1:7,  2:15, 3:16, 4:8,  5:2,  6:17, 7:18,\n",
    "    8:5, 9:9,10:27,11:28,12:10,13:23,14:25,15:26,\n",
    "   16:24,17:13,18:29,19:30,20:14,21:6, 22:21,23:22,\n",
    "   24:1,25:11,26:19,27:20,28:12,29:3\n",
    "}\n",
    "\n",
    "def compute_homography_pixel2field(label_path: str,\n",
    "                                   model_pts: np.ndarray,\n",
    "                                   pitch_cfg: PitchConfig,\n",
    "                                   img_shape: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads a YOLO‐kp label and returns H mapping (x_px, y_px, 1) →\n",
    "    (X_m, Y_m, w) so that [X_m, Y_m] are in metres [0..length],[0..width].\n",
    "    \"\"\"\n",
    "    img_h, img_w = img_shape[:2]\n",
    "    vals = list(map(float, open(label_path).read().split()))\n",
    "    kp   = np.array(vals[5:], dtype=np.float32).reshape(-1,3)\n",
    "\n",
    "    pts_img   = []\n",
    "    pts_model = []\n",
    "    for j,(xn,yn,vis) in enumerate(kp):\n",
    "        if vis <= 0 or j not in RF2MY:\n",
    "            continue\n",
    "        # pixel coordinates\n",
    "        x_px, y_px = float(xn * img_w), float(yn * img_h)\n",
    "        pts_img.append([x_px, y_px])\n",
    "        # meter coordinates\n",
    "        mx, my = model_pts[RF2MY[j]]\n",
    "        pts_model.append([mx, my])\n",
    "\n",
    "    pts_img   = np.array(pts_img,   dtype=np.float32)\n",
    "    pts_model = np.array(pts_model, dtype=np.float32)\n",
    "\n",
    "    if len(pts_img) < 4:\n",
    "        return None\n",
    "\n",
    "    # **DIRECT** mapping: pixels → metres\n",
    "    H_px2m, mask = cv2.findHomography(pts_img, pts_model,\n",
    "                                      cv2.RANSAC, ransacReprojThreshold=3.0)\n",
    "    if H_px2m is None:\n",
    "        return None\n",
    "\n",
    "    # normalize so H[2,2]==1\n",
    "    H_px2m /= H_px2m[2,2]\n",
    "    return H_px2m\n",
    "\n",
    "def clean_dataset_pixel2field(input_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Flattens train/valid/test into output_dir:\n",
    "      frame_000001.png\n",
    "      frame_000001_H.npy   (H_pixel2field)\n",
    "    \"\"\"\n",
    "    input_dir  = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # prepare model points once\n",
    "    fv        = FieldVisualizer(PitchConfig())\n",
    "    model_pts = fv.get_hardcoded_model_points()\n",
    "\n",
    "    idx = 0\n",
    "    for split in (\"train\",\"valid\",\"test\"):\n",
    "        imgs = sorted((input_dir/split/\"images\").glob(\"*\"))\n",
    "        for img_path in imgs:\n",
    "            lbl_path = input_dir/split/\"labels\"/f\"{img_path.stem}.txt\"\n",
    "            if not lbl_path.exists():\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            H = compute_homography_pixel2field(\n",
    "                    str(lbl_path), model_pts, img.shape)\n",
    "            if H is None:\n",
    "                print(f\"⚠ skipping {img_path.name}: <4 pts or bad H>\")\n",
    "                continue\n",
    "\n",
    "            idx += 1\n",
    "            out_img = output_dir/f\"frame_{idx:06d}.png\"\n",
    "            out_H   = output_dir/f\"frame_{idx:06d}_H.npy\"\n",
    "\n",
    "            cv2.imwrite(str(out_img), img)\n",
    "            np.save(str(out_H), H)\n",
    "\n",
    "    print(f\"✅ Wrote {idx} frames + H_pixel2field to {output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "clean_dataset_pixel2field(\n",
    "    \"data/00--raw/football-field-detection.v15i.yolov5pytorch\",\n",
    "    \"data/01--clean/roboflow-pixel2field\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ skipping 08fd33_0_9_png.rf.26e5e8716ff2eef771bbc7b876897685.jpg: <4 pts or no H>\n",
      "⚠ skipping 08fd33_6_2_png.rf.daab0ee8baa0b5090fe877bb30a00acf.jpg: <4 pts or no H>\n",
      "⚠ skipping 08fd33_6_4_png.rf.9c00c3899e6a1a4a8511162aea8ce223.jpg: <4 pts or no H>\n",
      "⚠ skipping 08fd33_3_5_png.rf.e7272099dcba3f202ae4da1010b8d7e2.jpg: <4 pts or no H>\n",
      "⚠ skipping 54745b_1_3_png.rf.77f1b370d7946cfc4b5d689bf13ad67d.jpg: <4 pts or no H>\n",
      "✅ Finished. Wrote 312 frames + normalized homographies to data/01--clean/roboflow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.visual.field import FieldVisualizer, PitchConfig\n",
    "\n",
    "# Roboflow→your‐model index mapping\n",
    "RF2MY = {\n",
    "    0:   0,\n",
    "    1:   7,\n",
    "    2:  15, \n",
    "    3:  16,\n",
    "    4:   8, \n",
    "    5:   2, \n",
    "    6:  17, \n",
    "    7:  18,\n",
    "    8:   5,\n",
    "    9:   9,\n",
    "    10: 27,\n",
    "    11: 28,\n",
    "    12: 10,\n",
    "    13: 23,\n",
    "    14: 25,\n",
    "    15: 26, \n",
    "    16: 24,\n",
    "    17: 13,\n",
    "    18: 29,\n",
    "    19: 30,\n",
    "    20: 14,\n",
    "    21:  6,\n",
    "    22: 21,\n",
    "    23: 22,\n",
    "    24:  1,\n",
    "    25: 11,\n",
    "    26: 19,\n",
    "    27: 20,\n",
    "    28: 12,# correct until now\n",
    "    29:  3,\n",
    "}\n",
    "\n",
    "\n",
    "def compute_homography_normalized(\n",
    "    label_path: str,\n",
    "    model_pts: np.ndarray,\n",
    "    img_shape: tuple,\n",
    "    pitch_cfg: PitchConfig\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads a YOLO‐kp label and returns H_norm mapping\n",
    "      [x_px/W, y_px/H, 1]^T → [X_m/L, Y_m/W, 1]^T\n",
    "    where L=length, W=width from pitch_cfg.\n",
    "    Both source and destination coordinates live in [0,1].\n",
    "    \"\"\"\n",
    "    H_px, W_px = img_shape[:2]\n",
    "    L, W       = pitch_cfg.length, pitch_cfg.width\n",
    "\n",
    "    vals = list(map(float, open(label_path).read().split()))\n",
    "    kp   = np.array(vals[5:], dtype=np.float32).reshape(-1, 3)\n",
    "\n",
    "    src_norm = []\n",
    "    dst_norm = []\n",
    "    for j, (xn, yn, vis) in enumerate(kp):\n",
    "        if vis <= 0 or j not in RF2MY:\n",
    "            continue\n",
    "        # normalized image coords\n",
    "        src_norm.append([xn, yn])\n",
    "        # normalized field coords\n",
    "        mx, my = model_pts[RF2MY[j]]\n",
    "        dst_norm.append([mx / L, my / W])\n",
    "\n",
    "    src_norm = np.array(src_norm, dtype=np.float32)\n",
    "    dst_norm = np.array(dst_norm, dtype=np.float32)\n",
    "    if len(src_norm) < 4:\n",
    "        return None\n",
    "\n",
    "    # solve in normalized space with a small reproj threshold\n",
    "    Hn, mask = cv2.findHomography(\n",
    "        src_norm, dst_norm,\n",
    "        method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=1e-3\n",
    "    )\n",
    "    if Hn is None:\n",
    "        return None\n",
    "\n",
    "    # normalize so Hn[2,2] == 1\n",
    "    Hn /= Hn[2,2]\n",
    "    return Hn.astype(np.float32)\n",
    "\n",
    "\n",
    "def clean_dataset_normalized(input_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Walk through train/valid/test under input_dir, compute normalized homography,\n",
    "    and write into output_dir:\n",
    "      frame_000001.png\n",
    "      frame_000001_Hnorm.npy\n",
    "    \"\"\"\n",
    "    input_dir  = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # prepare model points once\n",
    "    fv        = FieldVisualizer(PitchConfig())\n",
    "    model_pts = fv.get_hardcoded_model_points()\n",
    "    pitch_cfg = fv.config\n",
    "\n",
    "    idx = 0\n",
    "    for split in (\"train\", \"valid\", \"test\"):\n",
    "        img_folder = input_dir/split/\"images\"\n",
    "        lbl_folder = input_dir/split/\"labels\"\n",
    "        for img_path in sorted(img_folder.glob(\"*\")):\n",
    "            lbl_path = lbl_folder/f\"{img_path.stem}.txt\"\n",
    "            if not lbl_path.exists():\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            Hn = compute_homography_normalized(\n",
    "                str(lbl_path),\n",
    "                model_pts,\n",
    "                img.shape,\n",
    "                pitch_cfg\n",
    "            )\n",
    "            if Hn is None:\n",
    "                print(f\"⚠ skipping {img_path.name}: <4 pts or no H>\")\n",
    "                continue\n",
    "\n",
    "            idx += 1\n",
    "            out_img = output_dir/f\"frame_{idx:06d}.png\"\n",
    "            out_H   = output_dir/f\"frame_{idx:06d}_H.npy\"\n",
    "\n",
    "            cv2.imwrite(str(out_img), img)\n",
    "            np.save(str(out_H), Hn)\n",
    "\n",
    "    print(f\"✅ Finished. Wrote {idx} frames + normalized homographies to {output_dir}\")\n",
    "\n",
    "\n",
    "clean_dataset_normalized(\n",
    "    \"data/00--raw/football-field-detection.v15i.yolov5pytorch\",\n",
    "    \"data/01--clean/roboflow\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
