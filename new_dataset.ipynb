{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/00--raw/football-field-detection.v15i.yolov5pytorch/train/\"\n",
    "\n",
    "IMG_PATH = f\"{train_path}images/0a2d9b_2_3_png.rf.2b39030ff9f2e93a34aa9ca69abbd77c.jpg\"\n",
    "LBL_PATH = f\"{train_path}/labels/0a2d9b_2_3_png.rf.2b39030ff9f2e93a34aa9ca69abbd77c.txt\"\n",
    "\n",
    "# IMG_PATH = f\"{train_path}images/0a2d9b_6_11_png.rf.2cfd6b6dad39a0f39eee5eb3d729823f.jpg\"\n",
    "# LBL_PATH = f\"{train_path}/labels/0a2d9b_6_11_png.rf.2cfd6b6dad39a0f39eee5eb3d729823f.txt\"\n",
    "\n",
    "# right side\n",
    "# IMG_PATH = f\"{train_path}images/0a2d9b_7_14_png.rf.04beeed5de2d712614d10a1e75aae7b9.jpg\"\n",
    "# LBL_PATH = f\"{train_path}/labels/0a2d9b_7_14_png.rf.04beeed5de2d712614d10a1e75aae7b9.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# clean_kp_dataset.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.visual.field import PitchConfig, FieldVisualizer\n",
    "\n",
    "# ─── 1) YOUR mapping from Roboflow KP index → canonical model‐pt index ───\n",
    "#    Update this dict if you ever reorder your 33 reference points.\n",
    "RF2MY = {\n",
    "    0:   0,   1:   1,   2:   2,   3:   3,\n",
    "    4:   4,   5:   5,   6:   6,   7:   7,\n",
    "    8:   8,   9:   9,  10:  10,  11:  11,\n",
    "   12:  12,  13:  13,  14:  14,  15:  15,\n",
    "   16:  16,  17:  17,  18:  18,  19:  19,\n",
    "   20:  20,  21:  21,  22:  22,  23:  23,\n",
    "   24:  24,  25:  25,  26:  26,  27:  27,\n",
    "   28:  28,  29:  29,  30:  30,  31:  31\n",
    "}\n",
    "# (In this example it's identity—replace with your actual map!)\n",
    "\n",
    "def compute_homography_normalized(\n",
    "    lbl_path: Path,\n",
    "    model_pts: np.ndarray,\n",
    "    cfg: PitchConfig\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads one YOLO-KP .txt (format: class xc yc w h k0_x k0_y k0_v ...),\n",
    "    builds src_pts = [k.x, k.y] in [0,1], dst_pts = [X_i/L, Y_i/W],\n",
    "    then fits H_norm via RANSAC.\n",
    "    \"\"\"\n",
    "    vals = list(map(float, lbl_path.read_text().split()))\n",
    "    kp   = np.array(vals[5:], dtype=np.float32).reshape(-1,3)\n",
    "\n",
    "    src, dst = [], []\n",
    "    L, W = cfg.length, cfg.width\n",
    "\n",
    "    for j, (xn, yn, vis) in enumerate(kp):\n",
    "        if vis <= 0 or j not in RF2MY:\n",
    "            continue\n",
    "        src.append([xn, yn])\n",
    "        mx, my = model_pts[RF2MY[j]]\n",
    "        dst.append([mx / L, my / W])\n",
    "\n",
    "    src = np.asarray(src, dtype=np.float32)\n",
    "    dst = np.asarray(dst, dtype=np.float32)\n",
    "    if len(src) < 4:\n",
    "        return None\n",
    "\n",
    "    Hn, mask = cv2.findHomography(\n",
    "        src, dst,\n",
    "        cv2.RANSAC,\n",
    "        ransacReprojThreshold=1e-3\n",
    "    )\n",
    "    if Hn is None:\n",
    "        return None\n",
    "\n",
    "    # normalize so Hn[2,2] == 1\n",
    "    return (Hn / Hn[2,2]).astype(np.float32)\n",
    "\n",
    "\n",
    "def clean_dataset(\n",
    "    input_root: str,\n",
    "    output_root: str\n",
    "):\n",
    "    inp = Path(input_root)\n",
    "    out = Path(output_root)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # get your 33 reference pts in metre‐space\n",
    "    fv        = FieldVisualizer(PitchConfig())\n",
    "    model_pts = fv._reference_model_pts()  # [33×2]\n",
    "\n",
    "    idx = 0\n",
    "    for split in (\"train\",\"valid\",\"test\"):\n",
    "        img_dir = inp/ split / \"images\"\n",
    "        lbl_dir = inp/ split / \"labels\"\n",
    "        for img_path in sorted(img_dir.glob(\"*.png\")):\n",
    "            lbl_path = lbl_dir / f\"{img_path.stem}.txt\"\n",
    "            if not lbl_path.exists():\n",
    "                continue\n",
    "\n",
    "            Hn = compute_homography_normalized(lbl_path, model_pts, fv.cfg)\n",
    "            if Hn is None:\n",
    "                print(f\"⚠ skipping {img_path.name}: <4 visible pts>\")\n",
    "                continue\n",
    "\n",
    "            idx += 1\n",
    "            out_img = out / f\"frame_{idx:06d}.png\"\n",
    "            out_H   = out / f\"frame_{idx:06d}_H.npy\"\n",
    "            cv2.imwrite(str(out_img), cv2.imread(str(img_path)))\n",
    "            np.save(str(out_H), Hn)\n",
    "\n",
    "    print(f\"✅ Wrote {idx} samples to {out}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_dataset(\n",
    "        \"data/00--raw/football-field-detection.v15i.yolov5pytorch\",\n",
    "        \"data/01--clean/annotated_homographies\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
